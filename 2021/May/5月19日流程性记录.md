# 5月19日流程性记录

昨天看了2D光照，其中用到了Universal renderer pipeline，无论是URP还是可编程管线我都不太了解所以今天决定看一下渲染管线相关内容。

## 渲染管线

![img](https://pic3.zhimg.com/v2-579bdb7ac479bbbcf52358ca67725bd6_1440w.jpg?source=172ae18b)

渲染管线大致可以分为三个部分：

* 应用阶段
* 几何阶段
* 光栅化阶段

### 应用阶段

这个阶段由CPU负责，且完全可编程。

CPU将信息传给GPU，有些时候还会对这些信息进行剔除，在Shader中的`struct appdata_t`定义的就是从应用阶段传过来的信息，简单来说，需要从CPU获取什么信息，这个结构就声明需要包含什么信息，这些信息包括：

* 位置
* 切线
* 法线
* 最大四个纹理坐标，也就是UV坐标
* 颜色

纹理坐标表示为$(x,y,0,1)$，具体意义参考齐次坐标。

看到一个知乎的帖子说这个信息还能包括光照方向和光照颜色，但其实并不能，大概说一下如果要和光照进行互动的操作。首先Shader Lab的tags要声明`Tags{"LightMode=ForwardBase"}`，这个操作类似于namespace，这样管线就知道有`_WorldSpacewLightPos0`（光源方向），`_LightColor0`（光源颜色）可以使用，在这之后（不在应用阶段）可以用点乘运算来模拟光照效果。更进一步的环境光反射和阴影可以看Unity Documentation。

## 几何阶段

几何阶段由GPU处理，主要的流水线也是在这进行，其中有的流水线可以编程，有的不可以，以图中所示，绿色是完全可控，虚线外边框表示不是必需阶段，黄色表示可配置但不可控，紫色表示完全不可控。

### Draw Call

CPU在应用阶段把数据放在内存里，然后经过应用阶段的一系列操作后打包发给GPU处理。

具体来说，CPU会将一个模型和他的渲染指令（draw call）放入命令缓冲区，GPU取出然后处理。所以说白了，draw call就是CPU所调用的图形库接口。

然而过多的draw call会对帧率造成很大的影响，原因在于CPU的速度远不及GPU，也就是GPU处理太快了，CPU为了赶上这个速度会把大量时间花费在提交draw call上。

解决这个问题的方法是批处理，就是把很多小的draw call合成一个大的draw call一次提交，有两种实现方法：

* 静态，勾选Inspector的Static。这个做法是将不需要移动，旋转，缩放的物体设置为静态，这样他们会被打包一次性提交draw call。不过目前不知道2D里的sprite通过Animation替换算不算静态？感觉不算。除此之外从逻辑上来说，光源改变应该也算动态？（不过实验看来好像影响并不大）
* 动态，动态创建一样的物体。如果动态创建出来的prefab都有同样的材质，Unity会自己优化，但是动态批处理限制很多，稍微改一下大小都会破坏批处理。除此之外，顶点太多，Shader所需变量太多，多通道shader（前向渲染都支持多通道）等等都是威胁。

减少draw call是节省CPU资源的课题，除此之外节省CPU和GPU资源的方法还有很多，这里就先不赘述了，挖个坑。

### 顶点着色器（Vertex Shaders）

顶点着色器属于是老熟人了，这是GPU流水线的第一个阶段。

在顶点着色器中每一个顶点都会被独立对待，所以完全无法获取和别的顶点的关系。

除此之外这个阶段还负责模型转换和相机转换，也就是坐标空间到摄像机空间的映射。个人理解是以摄像机位置重新建立坐标系。

在顶点坐标系，可以做顶点位置变换和逐顶点的色彩信息处理，注意是信息处理，不是真的开始着色，只是为了着色计算一些信息。

### 几何着色器 （Geometry Shader）

其实在这之前还有个曲线细分着色器，个人感觉就是把原本的片元某条边之类的打个点继续分，但是这个功能几何着色器也能做，之后学习OpenGL再回过头看看。

几何着色器接收的输入是三个点数据和一个列表一样的数据集合，几何着色器的作用是对于已有点进行增删改，大概操作是将需要连接的节点添加到集合里，集合有：

* triStream
* lineStream
* pointStream

说一下添加到集合里会发生什么，以triStream为例，他会把相邻的三个节点两两相连组合成一个三角形比如集合里有$(1,2,3,4,5)$，那么triStream会连接$(1,2,3),(2,3,4),(3,4,5)$，为三个三角形。

### 投影

这个阶段GPU把三维空间映射到二维空间，GPU将从摄像机空间转换到齐次裁剪空间。

常见的投影方式有：透视投影与正交投影。这两种投影方式都要考虑远裁剪平面和近裁剪平面，透视需要额外考虑视野，也就是视锥体，正交要额外考虑尺寸，即视锥体底面大小。

定义：

* r，l代表左右
* t，b代表上下
* n，f代表远近

正交投影的矩阵如下，推导过程是将长方体的中心点移动到原点，然后缩放为一个各边都在$[-1,1]$范围的正方体
$$
M=
{\left[
\begin{array}{cccc}
\frac{2}{r-l} & 0 & 0 & -\frac{r+l}{r-l} \\
0 & \frac{2}{t-b} & 0 & -\frac{t+b}{t-b} \\
0 & 0 & \frac{2}{n-f} & -\frac{f+n}{f-n} \\
0 & 0 & 0 & 1
\end{array}
\right ]}
$$
透视投影的矩阵如下，推导过程是将远平面大小变换到和近平面一样，然后进行正交投影类似的变换，这里的FOV是field of view
$$
M=
{\left[
\begin{array}{cccc}
\frac{\cot\frac{FOV}{2}}{aspect} & 0 & 0 & 0 \\
0 & \cot\frac{FOV}{2} & 0 & 0 \\
0 & 0 & -\frac{f+n}{f-n} & -\frac{2fn}{f-n} \\
0 & 0 & -1 & 1
\end{array}
\right ]}
$$

### 裁剪

这一步把不需要的顶点裁剪不渲染，然后转换成二维空间，转换过程依赖于齐次坐标的$w$分量。

简单来说$w$分量的作用是：同一个物体再远处和近处渲染出来的大小$(x,y,z)$是不同的，但是$(x/w,y/w,z/w)$永远是相同的，为什么要多一个w，其实是为了解决33矩阵做不了平移运算的问题而引入的升维变量。

话说回来，裁剪要裁剪什么，判断顶点是否要被裁剪依赖于：
$$
x,y,z\in [-w,w]
$$
换句话说就是我们只要齐次空间中范围在$[-1,1]$里面的图像，而没有参与运算的$z$变量泽被写入了`z-buffer`里面，可以做一些关于顶点到摄像机的运算，个人目前能想到的就是雾的模拟。

### 屏幕映射

很简单，就是把其次空间$[-1,1]$映射到窗口坐标系。

## 光栅化阶段（Rasterization Stage）

### 图元组装 （Primitive Assembly）

通过收集的数据把点连成点，线或者三角形。

### 三角形遍历

这里检测屏幕上的某个像素是否被一个三角形网络覆盖，被覆盖的区域将生成一个片元（Fragment），如果某个像素并不能被一个三角形覆盖，此时可以根据需要来判断：

1. Standard Rasterization
2. Outer-conservative Rasterization
3. Inner-conservative Rasterization

这一阶段牵扯到了抗锯齿（Anti-aliasing）操作和深度插值计算操作（即多个三角形重叠的渲染规则的设定），总的来说这一步是给下一个步骤做准备，告诉下一阶段每个像素是如何被覆盖的。

### 片元着色器 （Fragment Shader）

老朋友二，这个阶段是完全可编程的，用于决定每个片元上应该是什么颜色。当然片元之间也是独立的。

### 逐片元操作 （Per-Fragment Operations）

这个阶段对每个片元进行操作，将它们的颜色以某种形式合并，主要工作有两项：测试和合并。

测试决定了片元会不会被显示出来，主要的测试有：

* 裁剪测试（Scissor Test）

  这个测试允许程序员开一个框，只有在框内的片元才会被显示。说实话感觉和裁剪阶段原理一样。

* 透明度测试（Alpha Test）

  好像被剔除了23333

* 模板测试（Stencil Test）

  模板测试中每个像素有一个stencilBuffer，里面会存一个模板值，默认为0。测试开始后，stencilBuffer会被拿来和所有在它上面的片元的模板值按照这个片元定义的规则进行对比，最后留下一个值，只有和这个值相等的颜色有机会被打印（究竟打不打印还得看后面其他的测试）。

  来看两个简单的代码

  ```hlsl
  Stencil {
    Ref 2
    Comp always
    Pass replace
  }
  ```

  这个表示，参考值为2，永远会通过测试，通过测试，stencilBuffer将被该片元替代。

  ```hlsl
  Stencil {
    Ref 2
    Comp equal
    Pass keep
    Zfail decrWrap
  }
  ```

  这个表示，如果和上面遮罩他的值一样，就会通过测试，通过测试之后，stencilBuffer将被保留不变。

  这个测试可以用于写描边高光功能，到时候可以参考（如果能想起来）。

### 深度测试 （Depth Test）

深度测试允许设置渲染物体之间的遮挡关系，根据不透明度进行混合也是在这里。

---

今天看这个花费了挺多时间的，主要是模板测试感觉挺有趣的。

接下来学习目标估计包括：

* Animation系统

* OpenGL，这个估计要很长一段时间学习了

* 材质

* 其他暂时还没想到，想到了再加

本来想做一下官方给的游戏demo分析，结果发现Linux缺少一些API什么的，跑不起来，先在Windows下回Unity好了，顺便试一下Rider在Windows的表现，个人感觉完全是Visual studio的上位替代。
